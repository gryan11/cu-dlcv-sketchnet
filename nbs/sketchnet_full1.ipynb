{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "import scipy.ndimage as im\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13250 images belonging to 250 classes.\n",
      "Found 6750 images belonging to 250 classes.\n",
      "256 256 1 250\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "\n",
    "data_root = '../data/tu-berlin/'\n",
    "train_data_dir = data_root + 'train'\n",
    "validation_data_dir = data_root + 'test'\n",
    "\n",
    "\n",
    "def enhance_edges(img):\n",
    "    k = np.ones((3,3))\n",
    "    k[1,1] = 4.0\n",
    "            \n",
    "    img = np.squeeze(img)    \n",
    "    factor = 1.0/img.max()\n",
    "    img = img * factor\n",
    "    for _ in xrange(3):\n",
    "        img[img < 0.8] = 0.0\n",
    "        img = im.convolve(img, k, mode='constant', cval=1.0)\n",
    "        factor = 1.0/img.max()\n",
    "        img = img * factor\n",
    "\n",
    "\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    return img\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        rotation_range=35,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=enhance_edges)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=enhance_edges)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "batch, y = train_generator.next()\n",
    "img_height = batch.shape[1]\n",
    "img_width = batch.shape[2]\n",
    "channels = batch.shape[3]\n",
    "num_classes = len(y[0])\n",
    "print img_height, img_width, channels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 270\n"
     ]
    }
   ],
   "source": [
    "print 13250/25, 6750/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "load_name = 'sketchnet_filtered2'\n",
    "with open('../models/'+load_name+'/model.json', 'r') as f:\n",
    "    model = keras.models.model_from_json(f.read())\n",
    "    model.load_weights('../models/'+load_name+'/best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer0 (Conv2D)              (None, 256, 256, 64)      640       \n",
      "_________________________________________________________________\n",
      "layer1 (Conv2D)              (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "layer2 (MaxPooling2D)        (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "layer4 (Conv2D)              (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "layer5 (MaxPooling2D)        (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "layer6 (Conv2D)              (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "layer7 (Conv2D)              (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "layer8 (MaxPooling2D)        (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "layer9 (Conv2D)              (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "layer10 (Conv2D)             (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "layer11 (MaxPooling2D)       (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "layer12 (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "layer13 (Dense)              (None, 1024)              134218752 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               256250    \n",
      "=================================================================\n",
      "Total params: 140,208,826\n",
      "Trainable params: 140,097,402\n",
      "Non-trainable params: 111,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = rmsprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'sketchnet_full1'\n",
    "%mkdir -p ../logs/{model_name}\n",
    "%mkdir -p ../models/{model_name}\n",
    "\n",
    "with open('../models/'+model_name+'/model.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "log_cb =\\\n",
    "    TensorBoard(log_dir='../logs/'+model_name+'/', \n",
    "                histogram_freq=0, \n",
    "                write_graph=False, write_images=False)\n",
    "best_model_cb =\\\n",
    "    ModelCheckpoint('../models/'+model_name+'/best.h5', \n",
    "                    monitor='val_acc', verbose=0, \n",
    "                    save_best_only=True, \n",
    "                    mode='auto', period=1)\n",
    "latest_model_cb =\\\n",
    "    ModelCheckpoint('../models/'+model_name+'/latest.h5', \n",
    "                    monitor='val_acc', verbose=0, \n",
    "                    period=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "reload(utils)\n",
    "\n",
    "trainer =  utils.ModelTrainer(\n",
    "                 model,\n",
    "                 'sketchnet_full1',\n",
    "                 opt,\n",
    "                 train_generator,\n",
    "                 validation_generator,\n",
    "                 train_steps=530,\n",
    "                 val_steps=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "530/530 [==============================] - 356s - loss: 5.6106 - acc: 0.0040 - val_loss: 5.5024 - val_acc: 0.0063\n"
     ]
    }
   ],
   "source": [
    "trainer.train(1, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/11\n",
      "530/530 [==============================] - 380s - loss: 5.3009 - acc: 0.0274 - val_loss: 4.4963 - val_acc: 0.1148\n",
      "Epoch 3/11\n",
      "530/530 [==============================] - 370s - loss: 4.4575 - acc: 0.1081 - val_loss: 3.5027 - val_acc: 0.2656\n",
      "Epoch 4/11\n",
      "530/530 [==============================] - 369s - loss: 3.8526 - acc: 0.1751 - val_loss: 3.1188 - val_acc: 0.3048\n",
      "Epoch 5/11\n",
      "530/530 [==============================] - 370s - loss: 3.5168 - acc: 0.2342 - val_loss: 2.8204 - val_acc: 0.3681\n",
      "Epoch 6/11\n",
      "530/530 [==============================] - 368s - loss: 3.2487 - acc: 0.2717 - val_loss: 2.6284 - val_acc: 0.3919\n",
      "Epoch 7/11\n",
      "529/530 [============================>.] - ETA: 0s - loss: 2.8405 - acc: 0.3454"
     ]
    }
   ],
   "source": [
    "trainer.train(10, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/530 [============================>.] - ETA: 0s - loss: 2.7010 - acc: 0.3792"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "trainer.train(10, 0.0002)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.train(10, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val ['loss', 'acc'] [2.1733131912019519, 0.51629630834967999]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(validation_generator, steps=135)\n",
    "print 'val', model.metrics_names, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/71\n",
      "530/530 [==============================] - 358s - loss: 2.1148 - acc: 0.4975 - val_loss: 1.9483 - val_acc: 0.5533\n",
      "Epoch 31/71\n",
      "530/530 [==============================] - 359s - loss: 2.0188 - acc: 0.5232 - val_loss: 1.9164 - val_acc: 0.5567\n",
      "Epoch 32/71\n",
      "530/530 [==============================] - 358s - loss: 1.9567 - acc: 0.5308 - val_loss: 1.8878 - val_acc: 0.5685\n",
      "Epoch 34/71\n",
      "530/530 [==============================] - 367s - loss: 2.0601 - acc: 0.5108 - val_loss: 1.9125 - val_acc: 0.5763\n",
      "Epoch 36/71\n",
      "529/530 [============================>.] - ETA: 0s - loss: 2.0203 - acc: 0.5248"
     ]
    }
   ],
   "source": [
    "trainer.train(50, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
