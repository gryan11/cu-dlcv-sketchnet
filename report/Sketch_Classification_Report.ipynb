{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Sketch Classification\n",
    "\n",
    "Gabriel Ryan (gr2547)\n",
    "\n",
    "Abhijit Suprem (asf2182)\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "Sketch classification is an inherently difficult problem due the lack of information in most sketches and inconsistencies in how objects are drawn. Unlike images, sketches usually don't include information about textures and others details, instead only having an outline of the object. In addition people will use varying levels of abstraction in their sketches, resulting in sketches that vary from fairly realistic representations to completely symbolic abstractions. This variation can be seen in the following examples of sketches of monkeys:\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"https://s3.amazonaws.com/gryan-content/dlcv_report/monkey2.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td> <img src=\"https://s3.amazonaws.com/gryan-content/dlcv_report/monkey1.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td> <img src=\"https://s3.amazonaws.com/gryan-content/dlcv_report/monkey3.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td> <img src=\"https://s3.amazonaws.com/gryan-content/dlcv_report/monkey4.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "While the first sketch seems fairly realistic, the following three sketches are increasingly abstract. However, these sketches still contain information in markings and shape of the face, belly, and tail that make them recognizable as monkeys in the middle two sketches. This suggests that when our brains perform classification and recognition, they are able to learn those abstractions from real life images of monkeys.\n",
    "\n",
    "This project replicates that process by using processed real life images to improve classification of sketches. Our hypothesis is that networks could learn to identify and pick out the same patterns that our brains do when recognizing an image, and thus be able to learn classify sketches even if that sketch does not directly resemble sketches used in training.\n",
    "\n",
    "The most widely used dataset for sketch classification is the TU-Berlin sketch dataset [1], which consists of 250 classes with 80 samples per class. The current best performance on it uses an ensemble of 5 networks that classify each step of the sketch and achieves an accuracy of 77.6% [2].\n",
    "\n",
    "We demonstrate that preprocessing images to resemble sketches and using them as additional training data for classification on the TU-Berlin dataset improves performance. Specifically, for the a 3 class sample of the dataset, we were able to go from 85.0 to 90.1% by incorporating processed images into the training data. Unfortunately, the image processing was time consuming and we were unable to process enough images to test more classes, however, we believe the substantial improvement of performance on this sample is a convincing proof of concept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketchification:\n",
    "\n",
    "In order to make images look like sketches, we trained a small network to perform binary classification of sketches using the Berkeley Segmentation Dataset and Benchmark [3]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "- explain filtering process and reasoning, demo on image from edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of concept test:\n",
    "\n",
    "### Results\n",
    "\n",
    "### Analysis\n",
    "- What were"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on full network:\n",
    "\n",
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution:\n",
    "\n",
    "Per pixel sketchification of images was developed primarily by Abhijit Suprem. I (Gabriel Ryan) primarily developed the image preprocessing and sketch recognition networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. asdf\n",
    "2. asdf\n",
    "3. Martin, David R. et al. “A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics.” ICCV (2001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
